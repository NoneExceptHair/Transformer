{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (generator): Linear(in_features=256, out_features=4555, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(5374, 256)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(4555, 256)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import math\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import time\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "model_pth = \"./models/\"\n",
    "model_name = \"transformer-5-22-2-best\"\n",
    "model = torch.load(model_pth + model_name + \".pth.tar\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The model has 7,667,147 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_base = \"./.data/multi30k/task1/raw/\"\n",
    "train_pths = ('train.de', 'train.en')\n",
    "val_pths = ('val.de', 'val.en')\n",
    "test_pths = ('test_2016_flickr.de', 'test_2016_flickr.en')\n",
    "train_filepaths = [(pth_base + pth) for pth in train_pths]\n",
    "test_filepaths = [(pth_base + pth) for pth in test_pths]\n",
    "\n",
    "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "de_vocab = build_vocab(train_filepaths[0], de_tokenizer, min_freq=3)\n",
    "en_vocab = build_vocab(train_filepaths[1], en_tokenizer, min_freq=3)\n",
    "\n",
    "BOS_IDX = de_vocab['<bos>']\n",
    "EOS_IDX = de_vocab['<eos>']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5374\n4555\n"
     ]
    }
   ],
   "source": [
    "print(len(de_vocab))\n",
    "print(len(en_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' a group of people standing in front of a <unk> sign . '"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "translate(model, \"eine gruppe von menschen steht vor einem iglu .\", de_vocab, en_vocab, de_tokenizer, BOS_IDX, EOS_IDX, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Reference and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load reference'''\n",
    "with open(test_filepaths[0], 'r', encoding='utf8') as f:\n",
    "    test_data = f.readlines()\n",
    "    \n",
    "'''update reference.txt'''\n",
    "with open(test_filepaths[1], 'r', encoding='utf8') as f:\n",
    "    reference = f.readlines()\n",
    "\n",
    "for i in range(len(reference)):\n",
    "    reference[i] = \" \".join(en_tokenizer(reference[i])).lower()\n",
    "\n",
    "with open(\"reference.txt\",'w+') as f:\n",
    "    f.writelines(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''make predictions'''\n",
    "predictions = []\n",
    "for data in test_data:\n",
    "    temp_trans = translate(model, data.lower(), de_vocab, en_vocab, de_tokenizer, BOS_IDX, EOS_IDX, device)\n",
    "    predictions.append((temp_trans[1:-3]+\" . \\n\"))\n",
    "\n",
    "'''update predictions.txt'''\n",
    "with open(\"predictions.txt\",'w+') as f:\n",
    "    f.writelines(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,pre in enumerate(predictions):\n",
    "    predictions[i] = pre.replace(\"<unk>\",\" \")\n",
    "'''update predictions.txt'''\n",
    "with open(\"predictions.txt\",'w+') as f:\n",
    "    f.writelines(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BLEU = 37.14, 70.6/45.7/30.7/21.1 (BP=0.976, ratio=0.977, hyp_len=12752, ref_len=13058)\n"
     ]
    }
   ],
   "source": [
    "! perl ./multi-bleu.perl -lc reference.txt < predictions.txt\n",
    "\n",
    "with open(model_pth + model_name + \".txt\",'w+') as f:    \n",
    "    f.writelines(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BLEU score = 33.84\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "references_corpus  = []\n",
    "candidate_corpus = []\n",
    "for pred,ref in zip(predictions, reference):\n",
    "    temp = pred.rstrip(\" \\n\").split(\" \")\n",
    "    candidate_corpus.append(temp)\n",
    "    temp = ref.rstrip(\" \\n\").split(\" \")\n",
    "    references_corpus.append([temp])\n",
    "bleu_torchtext = bleu_score(candidate_corpus, references_corpus)\n",
    "print(f'BLEU score = {bleu_torchtext*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['five', 'people', 'wearing', 'winter', 'jackets', 'and', 'helmets', 'stand', 'in', 'the', 'snow', ',', 'with', 'snowmobiles', 'in', 'the', 'background', '.']]\n['five', 'people', 'in', 'winter', 'jackets', 'and', 'helmets', 'are', 'standing', 'in', 'the', 'snow', 'with', '', '', 'in', 'the', 'background', '.']\n"
     ]
    }
   ],
   "source": [
    "print(references_corpus[3])\n",
    "print(candidate_corpus[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check BLEU from txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(model_pth + \"transformer-5-21-7-best\" + \".txt\",'r') as f:    \n",
    "#     predictions = f.readlines()\n",
    "\n",
    "# with open(\"predictions.txt\",'w+') as f:\n",
    "#     f.writelines(predictions)\n",
    "\n",
    "# ! perl ./multi-bleu.perl -lc reference.txt < predictions.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd07b4d25784dabc0ba7e8cce9dd958aedc39046ba310bddd7030ba48031f69b6c4",
   "display_name": "Python 3.8.8 64-bit ('ml': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}