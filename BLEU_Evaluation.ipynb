{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd07b4d25784dabc0ba7e8cce9dd958aedc39046ba310bddd7030ba48031f69b6c4",
   "display_name": "Python 3.8.8 64-bit ('ml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model Evaluation\n",
    "## Load Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (dropout3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (dropout3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (dropout3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=10838, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(19215, 512)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(10838, 512)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import math\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torch import Tensor\n",
    "import time\n",
    "import io\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(0)\n",
    "model_pth = \"./models/\"\n",
    "model_name = \"transformer-5-20-3-ckpt-90\"\n",
    "model = torch.load(model_pth + model_name + \".pth.tar\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The model has 43,016,278 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "source": [
    "## Build Vocabulary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_base = \"./.data/multi30k/task1/raw/\"\n",
    "\n",
    "train_pths = ('train.de.gz', 'train.en.gz')\n",
    "test_pths = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')\n",
    "\n",
    "train_filepaths = [extract_archive(pth_base + pth)[0] for pth in train_pths]\n",
    "test_filepaths = [extract_archive(pth_base + pth)[0] for pth in test_pths]\n",
    "\n",
    "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "de_vocab = build_vocab(train_filepaths[0], de_tokenizer, min_freq=1)\n",
    "en_vocab = build_vocab(train_filepaths[1], en_tokenizer, min_freq=1)\n",
    "\n",
    "BOS_IDX = de_vocab['<bos>']\n",
    "EOS_IDX = de_vocab['<eos>']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' A group of people stand in front of an igloo . '"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "translate(model, \"Eine Gruppe von Menschen steht vor einem Iglu .\", de_vocab, en_vocab, de_tokenizer, BOS_IDX, EOS_IDX, device)"
   ]
  },
  {
   "source": [
    "## Prepare Reference and Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load reference'''\n",
    "with open(test_filepaths[0], 'r', encoding='utf8') as f:\n",
    "    test_data = f.readlines()\n",
    "    \n",
    "'''update reference.txt'''\n",
    "with open(test_filepaths[1], 'r', encoding='utf8') as f:\n",
    "    reference = f.readlines()\n",
    "\n",
    "for i in range(len(reference)):\n",
    "    reference[i] = \" \".join(en_tokenizer(reference[i]))\n",
    "\n",
    "with open(\"reference.txt\",'w+') as f:\n",
    "    f.writelines(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''make predictions'''\n",
    "predictions = []\n",
    "for data in test_data:\n",
    "    temp_trans = translate(model, data, de_vocab, en_vocab, de_tokenizer, BOS_IDX, EOS_IDX, device)\n",
    "    predictions.append(temp_trans[1:-3]+\" . \\n\")\n",
    "\n",
    "'''update predictions.txt'''\n",
    "with open(\"predictions.txt\",'w+') as f:\n",
    "    f.writelines(predictions)"
   ]
  },
  {
   "source": [
    "## Calculate BLEU"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BLEU = 30.76, 60.6/37.1/24.3/16.4 (BP=1.000, ratio=1.142, hyp_len=14906, ref_len=13058)\n"
     ]
    }
   ],
   "source": [
    "! F:/ProgramData/Strawberry/perl/bin/perl.exe ./multi-bleu.perl -lc reference.txt < predictions.txt\n",
    "\n",
    "with open(model_pth + model_name + \".txt\",'w+') as f:    \n",
    "    f.writelines(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BLEU score = 30.53\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "references_corpus  = []\n",
    "candidate_corpus = []\n",
    "for pred,ref in zip(predictions, reference):\n",
    "    temp = pred.rstrip(\" \\n\").split(\" \")\n",
    "    candidate_corpus.append(temp)\n",
    "    temp = ref.rstrip(\" \\n\").split(\" \")\n",
    "    references_corpus.append([temp])\n",
    "bleu_torchtext = bleu_score(candidate_corpus, references_corpus)\n",
    "print(f'BLEU score = {bleu_torchtext*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['A', 'man', 'in', 'an', 'orange', 'hat', 'starring', 'at', 'something', '.']\n['A man in an orange hat starring at something . \\n']\n"
     ]
    }
   ],
   "source": [
    "print(en_tokenizer(reference[0].rstrip(\" \\n\")))\n",
    "print(reference[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['A', 'man', 'in', 'an', 'orange', 'hat', 'struggles', 'to', 'a', 'as', 'he', 'explores', 'something', '.']\n[['A', 'man', 'in', 'an', 'orange', 'hat', 'starring', 'at', 'something', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(candidate_corpus[0])\n",
    "print(references_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for ref in references_corpus[0]:\n",
    "    if len(ref)>max_len:\n",
    "        max_len = len(ref)\n",
    "print(max_len)"
   ]
  },
  {
   "source": [
    "### Check BLEU from txt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(model_pth + \"transformer-5-20-2-best\" + \".txt\",'r') as f:    \n",
    "#     predictions = f.readlines()\n",
    "\n",
    "# with open(\"predictions.txt\",'w+') as f:\n",
    "#     f.writelines(predictions)\n",
    "\n",
    "# ! F:/ProgramData/Strawberry/perl/bin/perl.exe ./multi-bleu.perl -lc reference.txt < predictions.txt"
   ]
  }
 ]
}