{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd07b4d25784dabc0ba7e8cce9dd958aedc39046ba310bddd7030ba48031f69b6c4",
   "display_name": "Python 3.8.8 64-bit ('ml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Project for Machine Learning\n",
    "- Key words: `NMT`, `Transformer`, `PyTorch`, `Multi30k`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.optim.lr_scheduler import StepLR,LambdaLR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from my_transformer import *\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "source": [
    "## Data Prerocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_base = \"./.data/multi30k/task1/raw/\"\n",
    "train_pths = ('train.de', 'train.en')\n",
    "val_pths = ('val.de', 'val.en')\n",
    "test_pths = ('test_2016_flickr.de', 'test_2016_flickr.en')\n",
    "\n",
    "train_filepaths = [(pth_base + pth) for pth in train_pths]\n",
    "val_filepaths = [(pth_base + pth) for pth in val_pths]\n",
    "test_filepaths = [(pth_base + pth) for pth in test_pths]\n",
    "\n",
    "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "de_vocab = build_vocab(train_filepaths[0], de_tokenizer, min_freq=3)\n",
    "en_vocab = build_vocab(train_filepaths[1], en_tokenizer, min_freq=3)\n",
    "\n",
    "train_data = data_process(train_filepaths, de_vocab, en_vocab, de_tokenizer, en_tokenizer)\n",
    "val_data = data_process(val_filepaths, de_vocab, en_vocab, de_tokenizer, en_tokenizer)\n",
    "test_data = data_process(test_filepaths, de_vocab, en_vocab, de_tokenizer, en_tokenizer)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)\n",
    "print(\"train size:\", len(train_data))\n",
    "print(\"val size:\", len(val_data))\n",
    "print(\"test size:\", len(test_data))\n",
    "print(\"de vocab size:\", len(de_vocab))\n",
    "print(\"en vocab size:\", len(en_vocab))"
   ]
  },
  {
   "source": [
    "## Hyper-parameters Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(de_vocab)\n",
    "TGT_VOCAB_SIZE = len(en_vocab)\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3 # no help, 3 is better\n",
    "NUM_DECODER_LAYERS = 3 # no help, 3 is better\n",
    "EMB_SIZE = 256\n",
    "FFN_HID_DIM = 512\n",
    "NHEAD = 8 # no help, hard converge\n",
    "DROPOUT = 0.1\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# LR_STEP = 30\n",
    "# warmup_steps = 4000\n",
    "model_name = \"./models/transformer-5-22-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = de_vocab['<pad>']\n",
    "BOS_IDX = de_vocab['<bos>']\n",
    "EOS_IDX = de_vocab['<eos>']\n",
    "\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=get_collate_fn(PAD_IDX,BOS_IDX,EOS_IDX))\n",
    "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=get_collate_fn(PAD_IDX,BOS_IDX,EOS_IDX))\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=get_collate_fn(PAD_IDX,BOS_IDX,EOS_IDX))"
   ]
  },
  {
   "source": [
    "## Model Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = MyTf(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, \n",
    "                   EMB_SIZE, NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, PAD_IDX,\n",
    "                   FFN_HID_DIM, DROPOUT)\n",
    "\n",
    "transformer = transformer.to(device)\n",
    "\n",
    "# lrate = lambda step_num: EMB_SIZE**-0.5 * np.minimum(step_num**-0.5,step_num*warmup_steps**-1.5)\n",
    "\n",
    "# scheduler = StepLR(optimizer, step_size=LR_STEP, gamma=0.1)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The model has {count_parameters(transformer):,} trainable parameters')"
   ]
  },
  {
   "source": [
    "## Train and Evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_curve = []\n",
    "val_loss_curve = []\n",
    "min_val_loss = 999\n",
    "steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train(transformer, train_iter, optimizer, loss_fn, device)\n",
    "    end_time = time.time()\n",
    "    val_loss = evaluate(transformer, valid_iter, loss_fn, device)\n",
    "#     scheduler.step()\n",
    "    \n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        transformer.eval()\n",
    "        torch.save(transformer, model_name+\"-best.pth.tar\")\n",
    "        \n",
    "    if epoch % 30 == 0:\n",
    "        transformer.eval()\n",
    "        torch.save(transformer, model_name+\"-ckpt-\"+str(epoch)+\".pth.tar\")\n",
    "        \n",
    "    train_loss_curve.append(train_loss)\n",
    "    val_loss_curve.append(val_loss)\n",
    "\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"min val loss:\",min_val_loss)\n",
    "plt.plot(train_loss_curve)\n",
    "plt.plot(val_loss_curve)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend((\"train loss\",\"val loss\"))\n",
    "plt.savefig(\"./images/\" + model_name.split(sep=\"/\")[-1] + \".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(transformer, \"eine gruppe von menschen steht vor einem iglu .\", de_vocab, en_vocab,de_tokenizer, BOS_IDX, EOS_IDX, device)"
   ]
  },
  {
   "source": [
    "## Save the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.eval()\n",
    "torch.save(transformer, model_name + \".pth.tar\")"
   ]
  },
  {
   "source": [
    "## Calculate the BLEU Score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load reference'''\n",
    "with open(test_filepaths[0], 'r', encoding='utf8') as f:\n",
    "    test_data_ = f.readlines()\n",
    "    \n",
    "'''make predictions'''\n",
    "predictions = []\n",
    "for data in test_data_:\n",
    "    temp_trans = translate(transformer, data.lower(), de_vocab, en_vocab, de_tokenizer, BOS_IDX, EOS_IDX, device)\n",
    "    predictions.append(temp_trans[1:-3]+\" . \\n\")\n",
    "\n",
    "'''update predictions.txt'''\n",
    "with open(\"predictions.txt\",'w+') as f:\n",
    "    f.writelines(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''eliminate <unk>''' \n",
    "# for i,pre in enumerate(predictions):\n",
    "#     predictions[i] = pre.replace(\"<unk>\",\" \")\n",
    "# '''update predictions.txt'''\n",
    "# with open(\"predictions.txt\",'w+') as f:\n",
    "#     f.writelines(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! perl ./multi-bleu.perl -lc reference.txt < predictions.txt\n",
    "\n",
    "with open(model_name + \".txt\",'w+') as f:    \n",
    "    f.writelines(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "references_corpus  = []\n",
    "candidate_corpus = []\n",
    "'''update reference.txt'''\n",
    "'''update reference.txt'''\n",
    "with open(test_filepaths[1], 'r', encoding='utf8') as f:\n",
    "    reference = f.readlines()\n",
    "\n",
    "for i in range(len(reference)):\n",
    "    reference[i] = \" \".join(en_tokenizer(reference[i])).lower()\n",
    "\n",
    "for pred,ref in zip(predictions, reference):\n",
    "    temp = pred.rstrip(\" \\n\").split(\" \")\n",
    "    candidate_corpus.append(temp)\n",
    "    temp = ref.rstrip(\" \\n\").split(\" \")\n",
    "    references_corpus.append([temp])\n",
    "bleu_torchtext = bleu_score(candidate_corpus, references_corpus)\n",
    "print(f'BLEU score = {bleu_torchtext*100:.2f}')"
   ]
  }
 ]
}